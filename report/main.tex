\documentclass[10pt,twocolumn]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{cite}
\geometry{margin=1in}

\title{Improving Model Inversion Attacks Using Additional Backbones}
\author{Christopher Roßbach \\ FAU-Erlangen-Nürnberg}
\date{\today}

\begin{document}

\maketitle
\begin{abstract}
    Model inversion attacks aim to infer sensitive information about input or training data from the outputs or representations of machine learning models.
    In this work we explore model inversion in the form of reconstructing images from their feature embeddings in a known latent space.
    We explore the effectiveness of optimization based methods in different latent spaces.
    Using the discovered findings, we propose a method that leverages the embeddings of multiple reconstruction candidates in foreign latent spaces to improve reconstruction quality.
\end{abstract}

\section{Introduction}
Model inversion attacks pose significant risks by reconstructing private information about either training data or model inputs.
This report investigates techniques that try to reconstruct the full model input from a latent representation.
We limit ourselves to the task of image reconstruction from feature embeddings given by a pretrained vision backbone.
We assume a white-box setting where the attacker has access to the model architecture and parameters as well as the feature embedding of the target image.

We aim to approximate the private image $x^*$ owned by the victim from its embedding $y^* = f(x^*)$ where $f$ is a pretrained known backbone network and $y^*$ is the embedding known to the attacker (either leaked or purposely shared).

\section{Related Work}
Brief overview of previous research on model inversion attacks and defense mechanisms.


\section{Methodology}
We try to reconstruct the private image from its embedding through an optimization process.
The problem of reconstructing the private image from its embedding is a strongly ill posed which forces us to incorporate additional constraints and priors to the optimization process.
The optimization problem can be formulated as
$$
\min_{\hat{x}} d_f(f(\hat{x}), y^*) + \mathcal{R}(\hat{x}),
$$
where $\mathcal{R}$ is a regularization term that encourages the reconstruction to be smooth and natural and is further described in Section~\ref{reg}.
$d_f$ is a distance function that is dependent on the used backbone $f$.
For a ResNet backbone we use the mean squared error (MSE) as the distance function while using a cosine based distance for a clip encoder.
\subsection{The Iterative Base Method}\label{base_method}
We employ an iterative optimization method to progressively refine the reconstruction.
We generally optimize in the image space while resorting to a lower dimensional image space at the beginning of the reconstruction.
Successive upscaling encourages the reconstruction of coarse structures before refining details.
We take the resolution steps used in~\cite{kazemiWhatWeLearn2024} and find adding another low resolution step of 32 to be beneficial, resulting in a scale sequence of $n\in\{32, 64, 128, 224\}$ where upscaling is performed at steps 400, 900 and 1800.

At each iteration, we update the reconstruction $x$ in the possibly smaller space $\mathbb{R}^{3\times n \times n}$ from which we retrieve the full size reconstruction proposal $\mathbb{R}^{3\times N \times N}\ni\hat{x} = S_N(x)$ by using a differentiable scaling function $S_k:\mathbb{R}^{3\times n \times n}\rightarrow\mathbb{R}^{3\times k \times k}$.
The next reconstruction $x$ is determined by
$$
x^{(t)} = S_{n_t}\left(x^{(t-1)} - \eta \dfrac{\nabla \mathcal{L}(x^{(t-1)}, y^*)}{\|\nabla \mathcal{L}(x^{(t-1)}, y^*)\|_2}\right),
$$
where $t$ denotes the iteration step, $n_t$ the resolution at step $t$, $\eta$ is the learning rate, and $\mathcal{L}$ the loss function.
This process is repeated for 3000 iterations after which no notable improvement was noticed in practice.

For now, the loss function $\mathcal{L}$ is defined as
$$
\mathcal{L}(x, y^*) = d(f(A(S_N(x))), y^*) + \mathcal{R}(S_N(x)),
$$
where $A$ is a randomized augmentation function as described in Section~\ref{augs}, and $d$ is a distance function that is dependent on the used backbone $f$ and $\mathcal{R}$ is a regularization term as described in Section~\ref{reg}.

\subsection{Augmentations}\label{augs}
As proposed in~\cite{ghiasiPlugInInversionModelAgnostic2021} we employ a set of differentiable augmentations to improve the robustness of the reconstruction.
We expect the embedding to be stable under (slight) scaling, rotation and translation.
We incorporate these augmentations into the optimization process as a prior by applying a (different) set of augmentations at each step of the optimization.
The transformation is thereby chosen randomly from $(\text{scale}, \text{rotate}, \text{translate}_h, \text{translate}_v) \in \lbrack 0.7, 1.5\rbrack\times \lbrack -30, 30\rbrack \times \lbrack -0.1, 0.1\rbrack \times \lbrack -0.1, 0.1\rbrack$.

\subsection{Regularization}\label{reg}
For regularization we use a term based on total variation as proposed in~\cite{mahendranUnderstandingDeepImage2015} with the adjustment of using a $L_1$ distance:
$$
\mathcal{R}(x) = g_{\alpha,\beta}\left(\dfrac{\mathcal{R}_{TV}(x)}{(n-1)^2}\right)
$$
with
$$
\mathcal{R}_{TV}(x) = \sum_{i,j} \left| x_{i,j} - x_{i + 1,j} \right| + \left| x_{i,j} - x_{i,j + 1} \right|.
$$
This term is used to penalize sharp edges in the reconstructed images.
Here $n$ refers to the width of the square image and $g_{\alpha,\beta}$ is a penalty function that balances the contribution of the total variation term and is defined as:
$$
g_{\alpha,\beta}(x) = \text{relu}(x - \alpha) + \beta\cdot\text{relu}(x - \alpha) ^ 2.
$$
This quadratic dead zone penalty function allows for punishment-free variation in the interval $\lbrack-\alpha,\alpha\rbrack$ and (for big enough $\beta$) limits the total variation to be close to $\alpha$.
The use of this penalty function makes sure, that the this regularization term does not loose importance when adding additional terms to the objective function of the optimization.
A parameter selection of $\alpha = 0.3$ and $\beta = 10$ was found to yield good results in practice.\footnote{We could pin this to the avg value of e.g. Imagenet Data.}

\section{Experiments}
\subsection{Impact of Inverted Model}
The reconstruction method described in Section~\ref{base_method} yields visibly different results when using different backbones $f$.
It is to note, that the reconstruction for different backbones does not strictly yield better or worse reconstructions, but rather reconstruction with qualitatively different details.
This effect can be seen in figure~\ref{fig:resnet_vs_clip}.

For the picture of the safe, we note that the reconstruction on a ResNet backbone gives a picture containg structural properties of a safe, while the reconstruction on the clip embedding seems to reproduce the text contained in the lower right corner of original picture.
For the dog picture, the reconstruction based on the clip embedding yields a better representation of the dog's features compared to the ResNet based reconstruction, while the ResNet reconstruction contains patterns of the background.
In the reconstruction of the fish picture the ResNet based reconstruction focuses on the fish's shape and the hands while the clip based reconstruction reconstructs the face of the person holding the fish.

From this observation we conclude, that a improvement in reconstruction quality can be achieved by combining different backbones in the reconstruction process while maintaining the assumption to have access to a single embedding.
\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{figures/resnet-vs-clip.png}
    \caption{
        Comparison of reconstructions on ResNet and CLIP backbones.
    }
    \label{fig:resnet_vs_clip}
\end{figure}

\subsection{Average of Foreign Embeddings}
Another important observation is that if we have two different backbones $f$ and $h$, a private image $x^*$ and a slightly modified version $x^*_p$ of the private image for which $f(x^*)\approx f(x^*_p)$ then we also observe $h(x^*)\approx h(x^*_p)$.
That is, if we modify the private image only slightly, the embeddings produced by different backbones remain consistent.
However, this behaviour does not apply to reconstructions: for a reconstruction $\hat x_f$ obtained by procedure described in~\ref{base_method} with respect to the backbone $f$ that suffices $f(\hat x_f)\approx f(x^*)$ we observe strong differences in the embedding under $h$, $d_h(h(\hat x_f),h(x^*)) \gg d_f(f(\hat x_f),f(x^*))\approx 0$.
The same is true for two different reconstructions $\hat x_{f,0}$ and $\hat x_{f,1}$: while $f(\hat x_{f,0})\approx f(\hat x_{f,1})$ we observe $h(\hat x_{f,0})\not\approx h(\hat x_{f,1})$.

Furthermore, if we have a set of reconstruction $X_f = \{\hat x_{f,0}, \hat x_{f,1}, \dots\}$ we observe that that the average embedding under $h$ of the reconstructions $X_f$ is closer to the embedding und $h$ of the private image then the average distance of the reconstructions: $$d_h\left(\overline{h(X_f)}, h(x^*)\right) < \overline{d_h(h(X_f), h(x^*))}.$$
We often observe the even stronger statement, that the averaged embedding is closer to the embedding of the private image then every single reconstruction: $$\forall\hat x \in X_f: d_h\left(\overline{h(X_f)}, h(x^*)\right) < d_h(h(\hat x), h(x^*)).$$
This effect can be seen in figure~\ref{fig:avg_distance_scatter}.
\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{figures/avg-distance-scatter.png}
    \caption{
       Comparison of embedding distances for noised images, reconstructions and averaged reconstruction embeddings for $f$ being a ResNet backbone, and $h$ being a VGG backbone (left) and $h$ being a CLIP backbone (right).
    }
    \label{fig:avg_distance_scatter}
\end{figure}

That leads to the intuitive assumption the that embeddings under a foreign backbone $h$ scatter around the embedding of the private image $h(x^*)$ and do not deviate in a specific direction.
This idea is illustrated in figure~\ref{fig:avg_embedding_sketch}.
\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{figures/avg-embedding-sketch.png}
    \caption{
       Illustration of the imagined scattering behavior of embeddings under a backbone used for reconstruction $f$ (left) and a foreign backbone $h$ (right).
       The average embedding in the foreign space is closer to the embedding of the private image than the embeddings of the reconstructions.
    }
    \label{fig:avg_embedding_sketch}
\end{figure}

\subsection{Combining Multiple Backbones}
To potentially make use of this we explored multiple methods to incorporate the average in the foreign embedding space during the reconstruction process.

Since most of the used networks apply a ReLu activation to their outputs, simply calculating the arithmetic average in each coordinate leads to a huge distribution shift of the embeddings.
To reduce that shift, we can perform the averaging in the latent space before applying the ReLu activation.
The effect of this can bee seen in figure~\ref{fig:relu_norelu_distribution_shift}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{figures/relu-norelu-distribution-shift.png}
    \caption{
       Distribution of embeddings in different backbones.
       Top: Average calculated after ReLu activation.
       Bottom: Average calculated before ReLu activation.
    }
    \label{fig:relu_norelu_distribution_shift}
\end{figure}

\section{Results}
Presentation and analysis of experimental results. Include tables and figures as needed.

\section{Discussion}
Interpretation of results, limitations, and potential improvements.
\begin{itemize}
    \item only approximate components with high agreement in foreign space
    \item difference between in and ood data
\end{itemize}

\section{Conclusion}
Summary of findings and suggestions for future work.

\bibliographystyle{plain}
\bibliography{references}

\end{document}